# Lesson 7: Generative Adversarial Networks (GANs)

**1. Introduction to GANs**

Generative Adversarial Networks (GANs) are a type of generative model that learn to generate realistic data by training two neural networks in a competitive setting: a generator and a discriminator. The generator learns to create realistic samples, while the discriminator learns to distinguish between real data samples and those generated by the generator. The two networks are trained simultaneously, with the generator trying to fool the discriminator and the discriminator trying to correctly classify samples.

**2. Generator and Discriminator Networks**



* Generator: The generator network takes random noise as input and generates an output resembling the target data distribution. The goal of the generator is to produce samples that can fool the discriminator.
* Discriminator: The discriminator network takes both real data samples and generated samples as input and tries to classify them as either real or fake. The goal of the discriminator is to correctly identify whether a given sample is real or generated by the generator.

**3. Loss Functions and Training GANs**

Training GANs involves optimizing two separate loss functions: one for the generator and one for the discriminator. The generator's loss aims to maximize the probability that the discriminator misclassifies generated samples as real. The discriminator's loss aims to maximize the probability of correctly classifying real and generated samples.

Typically, GANs are trained using the binary cross-entropy loss function. The training process involves alternating between updating the discriminator and the generator. In each iteration, the discriminator is updated using a mix of real and generated samples, while the generator is updated using the discriminator's classification of its generated samples.

**4. Implementing a GAN for Image Synthesis**

Here's an example of a simple GAN implementation in PyTorch for image synthesis:


```python
import torch
import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, noise_dim, output_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(noise_dim, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim),
            nn.Tanh(),
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, input_dim):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        return self.model(x)

noise_dim = 100
input_dim = 784  # Example: 28x28 images flattened to a 1D vector
gen = Generator(noise_dim, input_dim)
disc = Discriminator(input_dim)
```


In this example, we define two simple fully connected networks for the generator and discriminator. The generator takes random noise as input and generates a flattened image, while the discriminator takes the flattened image as input and outputs a probability indicating whether the input is real or generated.

Training the GAN involves alternating between updating the discriminator and the generator:

```python

import torch.optim as optim

gen_optimizer = optim.Adam(gen.parameters(), lr=0.0002)

disc_optimizer = optim.Adam(disc.parameters(), lr=0.0002)

criterion = nn.BCELoss()

# Assuming you have your training data loader named 'train_loader'

num_epochs = 10

for epoch in range(num_epochs):

    for batch_idx, (real_images, _) in enumerate(train_loader):

        real_images = real_images.view(-1, input_dim)

        batch_size = real_images.size(0)

        # Update the discriminator

        disc_optimizer.zero_grad()
        real_labels = torch.ones(batch_size, 1)
        real_preds = disc(real_images)
        real_loss = criterion(real_preds, real_labels)

        noise = torch.randn(batch_size, noise_dim)
        generated_images = gen(noise)
        fake_labels = torch.zeros(batch_size, 1)
        fake_preds = disc(generated_images.detach())  # Detach to avoid updating the generator
        fake_loss = criterion(fake_preds, fake_labels)

        disc_loss = real_loss + fake_loss
        disc_loss.backward()
        disc_optimizer.step()

        # Update the generator
        gen_optimizer.zero_grad()

        gen_labels = torch.ones(batch_size, 1)  # Generator wants to fool the discriminator
        gen_preds = disc(generated_images)  # Reuse the generated images
        gen_loss = criterion(gen_preds, gen_labels)

        gen_loss.backward()
        gen_optimizer.step()
```


In this training loop, we first update the discriminator using real images and generated images. The discriminator's loss is the sum of the binary cross-entropy losses for real and generated samples. Then, we update the generator using the discriminator's classification of the generated images. The generator's loss is the binary cross-entropy loss for the generated images, but with the target labels set to 1, as the generator's goal is to fool the discriminator into thinking its samples are real.

By training the generator and discriminator in this alternating fashion, the GAN will learn to generate increasingly realistic images over time.


## Exercises:**

1. Implement a GAN for an image dataset (e.g., MNIST or CIFAR-10) using PyTorch. Train the GAN and analyze the quality of the generated images. Experiment with different generator and discriminator architectures, as well as training strategies, to improve the performance of the GAN.
2. Implement a Deep Convolutional GAN (DCGAN) by replacing the fully connected layers in the generator and discriminator with convolutional layers. Train the DCGAN on an image dataset (e.g., MNIST or CIFAR-10) and analyze the quality of the generated images.
3. Train a GAN with different loss functions (e.g., Wasserstein loss, Least Squares loss) and compare the quality of the generated images and the stability of the training process.
4. Implement a conditional GAN, which takes both the input noise and a label as input, and use it for controlled image generation (e.g., generating images of a specific class). Compare the performance and generative capabilities of the conditional GAN to the vanilla GAN.
5. Implement a GAN for a different type of data, such as text or audio. Analyze the challenges and limitations of applying GANs to non-image data.
6. Experiment with GAN variants, such as InfoGAN, CycleGAN, or StyleGAN, and analyze their properties, strengths, and weaknesses in comparison to vanilla GANs and DCGANs.