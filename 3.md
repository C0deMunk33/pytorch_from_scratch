# Lesson 3: Convolutional Neural Networks (CNNs)

**1. Introduction to CNNs**

Convolutional Neural Networks (CNNs) are a type of neural network specifically designed for processing grid-like data, such as images. They are widely used for various computer vision tasks, such as image classification, object detection, and segmentation. CNNs are built using a combination of convolutional layers, pooling layers, and fully connected layers.

**2. Convolutional Layers**

Convolutional layers are the core building blocks of CNNs. They apply a set of filters (also known as kernels) to the input data, which allows the network to learn and detect local patterns, such as edges, textures, and shapes. A filter is a small matrix of weights that slides over the input data, computing the dot product between the filter and the input at each position.

The main hyperparameters of a convolutional layer are:



* Number of filters: Determines the number of output feature maps.
* Filter size: The height and width of the filters. Common sizes are 3x3, 5x5, and 7x7.
* Stride: The step size the filter takes while sliding over the input. A larger stride results in a smaller output size.
* Padding: Adding extra pixels around the input to control the output size. Padding can be "same" (output has the same size as input) or "valid" (no padding is applied).

**3. Pooling Layers**

Pooling layers are used to reduce the spatial dimensions of the feature maps and control the number of parameters in the network. They aggregate local features and provide a form of translation invariance. The most common pooling operation is max pooling, which takes the maximum value in a local neighborhood. Average pooling, which computes the average value in a local neighborhood, is another option.

The main hyperparameters of a pooling layer are:



* Pooling type: Max or average pooling.
* Pooling size: The height and width of the pooling window (e.g., 2x2 or 3x3).
* Stride: The step size the pooling window takes while sliding over the input.

**4. Implementing a CNN for Image Classification**

Here's an example of implementing a simple CNN for image classification using PyTorch:


``` python

import torch

import torch.nn as nn

import torch.optim as optim

class SimpleCNN(nn.Module):

    def __init__(self, num_classes):

        super(SimpleCNN, self).__init__()

        

        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)

        self.relu1 = nn.ReLU()

        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        

        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)

        self.relu2 = nn.ReLU()

        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        

        self.fc = nn.Linear(32 * 8 * 8, num_classes)

    def forward(self, x):

        x = self.pool1(self.relu1(self.conv1(x)))

        x = self.pool2(self.relu2(self.conv2(x)))

        x = x.view(x.size(0), -1)

        x = self.fc(x)

        return x

# Example usage:

num_classes = 10

model = SimpleCNN(num_classes)

input_data = torch.randn(32, 3, 32, 32)  # Batch of 32 RGB images of size 32x32

output = model(input_data)

# Training the model

Criterion = nn.CrossEntropyLoss()

optimizer = optim.Adam(model.parameters(), lr=0.001)

# Assuming you have your training and validation data loaders

# named 'train_loader' and 'val_loader'

num_epochs = 10

for epoch in range(num_epochs):

    model.train()

    

    # Training loop

    for batch_idx, (inputs, targets) in enumerate(train_loader):

        optimizer.zero_grad()

        outputs = model(inputs)

        loss = criterion(outputs, targets)

        loss.backward()

        optimizer.step()

    # Validation loop

    model.eval()

    total_correct = 0

    total_samples = 0

    with torch.no_grad():

        for batch_idx, (inputs, targets) in enumerate(val_loader):

            outputs = model(inputs)

            _, predicted = torch.max(outputs.data, 1)

            total_samples += targets.size(0)

            total_correct += (predicted == targets).sum().item()

    accuracy = 100.0 * total_correct / total_samples

    print(f"Epoch {epoch+1}/{num_epochs}, Validation accuracy: {accuracy:.2f}%")
```

In this example, we have a simple CNN with two convolutional layers followed by ReLU activation functions and max-pooling layers. After the convolutional layers, we have a fully connected layer that maps the features to the output classes. We train the model using the cross-entropy loss and the Adam optimizer. The training and validation loops are also provided, and the validation accuracy is printed at the end of each epoch.


## Exercises:

1. Implement a CNN for image classification using PyTorch on a real-world dataset, such as CIFAR-10 or Fashion-MNIST. Experiment with different architectures and hyperparameters to improve the model's performance.
2. Add batch normalization to your CNN implementation from Exercise 1. Analyze the impact of batch normalization on the model's training speed and performance.
3. Modify your CNN implementation from Exercise 1 to use average pooling instead of max pooling. Compare the performance of the two models and discuss the differences between max pooling and average pooling.
4. Experiment with different filter sizes in the convolutional layers of your CNN implementation from Exercise 1. Analyze the impact of using larger or smaller filters on the model's performance and computational complexity.
5. Implement a deeper CNN architecture for image classification, such as VGG or ResNet, using PyTorch. Compare the performance of your deeper CNN with the simple CNN from Exercise 1.
6. Apply data augmentation techniques, such as random rotations, flips, or translations, to the training images in your CNN implementation from Exercise 1. Analyze the impact of data augmentation on the model's performance and its ability to generalize.
1. 